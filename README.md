# hktn

изначально пробовали обучать нейронку на собственном железе, но быстро поняли, что этот вариант не подойдет.

в качестве виртуальной машины использовали мощности Kaggle. для сбора аналитики использовали API Weights & Basis (wandb.ai).

так же пробовали организовать работу через Roboflow и ClearML, но посчитали решения выше более удобными.

p.s. на нормальные коммиты, документацию, чистую архитектуру и рефакторинг не хватило времени...

p.s.p.s. сегодня при коммите произошли неприятности и все сегодняшние апдейты канули в лету. то есть более чистый код и обновленный датасет, который находится на домашнем пк. сегодня вечером все докинем. так же мы не успели поработать с ветками и архитектурой.

upd 14:14: мы нашли решение, прикрепить наши бекап датасеты с Kaggle.

обновленный расширенный датасет (склеили первый и новый): https://www.kaggle.com/datasets/timofeybasuev/mainmainmain/data
первый датасет: https://www.kaggle.com/datasets/timofeybasuev/pancir-case/data


## Kaggle

```python
!pip install ultralytics
```

```python
from ultralytics import YOLO

model = YOLO(<model path>)

results = model.train(
   data='<data yaml path>',
   imgsz=640,
   epochs=50,
   batch=32, # изначально подавали по 8, но потыкались и 32 оказался продуктивнее всех
   name='hktn')
```
